{
 "metadata": {
  "name": "",
  "signature": "sha256:dc765aa3c86b0aeff7bf390d9dd87f6b51f1aaeb64a7395cfe091981ee00e139"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "%matplotlib inline\n",
      "\n",
      "from nltk.tokenize import sent_tokenize\n",
      "from nltk.tokenize import TreebankWordTokenizer\n",
      "from textblob import TextBlob\n",
      "\n",
      "from collections import Counter\n",
      "from operator import itemgetter\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "from nltk.util import ngrams\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt = open(\"../Kojak/paul_graham.txt\").read().decode('utf-8')\n",
      "txt = txt.replace('\\n', \"\")\n",
      "sentences = sent_tokenize(txt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = TreebankWordTokenizer()\n",
      "\n",
      "stop = stopwords.words(\"english\")\n",
      "stop += ['.', ',', '(', ')', \"'\", '\"', \"?\", \"-\", \"!\", \"*\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter = Counter()\n",
      "\n",
      "for word in txt:\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}